from functools import wraps
import datetime
from nvitop import select_devices, Device, GpuProcess, NA
import time
import os
from loguru import logger
import json
from redis import Redis
import psutil
import subprocess

REDIS_PATH = ""

class RedisClient:
    def __init__(self):
        self.client = Redis(
            host="127.0.0.1",
            port=6379,
            decode_responses=True,
            encoding="UTF-8",
        )
        is_start = False
        try:
            response = self.client.ping()
            is_start = True
        except Exception as e:
            pass
        if not is_start:
            logger.warning("RedisæœåŠ¡å™¨è¿žæŽ¥å¤±è´¥ï¼Œå°è¯•å¯åŠ¨æœåŠ¡...")
            # æ•èŽ·å‘½ä»¤è¾“å‡º
            subprocess.run(
                [
                    REDIS_PATH + "/bin/redis-server",
                    REDIS_PATH + "/bin/redis.conf",
                ],
                capture_output=True,
                text=True,
                check=True,
            )
            time.sleep(5)
            response = self.client.ping()
            if response is None:
                raise Exception("RedisæœåŠ¡å™¨å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥Redisæ˜¯å¦æ­£ç¡®å®‰è£…ï¼")

    def get_self_occupied_gpus(self, only_gpus=True):
        """
        èŽ·å–è‡ªå·±å·²ç»å ç”¨çš„Gpuåºå·
        """
        self_occupied_gpus = self.client.hgetall("running_processes")
        if only_gpus:
            all_gpus = []
            for task in self_occupied_gpus.values():
                gpus = [
                    int(device) for device in str(json.loads(task)["cuda"]).split(",")
                ]
                all_gpus.extend(gpus)
            return list(set(all_gpus))
        return [json.loads(g) for g in self_occupied_gpus.values()]

    def join_wait_queue(self, id, n_gpus, memo):
        """
        åŠ å…¥ç­‰å¾…é˜Ÿåˆ—
        """
        curr_time = datetime.datetime.now()
        creat_time = datetime.datetime.strftime(curr_time, "%Y-%m-%d %H:%M:%S")
        content = {
            "n_gpus": n_gpus,
            "create_time": creat_time,
            "update_time": creat_time,
            "system_pid": os.getpid(),
            "id": id,
            "task_desc": memo,
        }
        wait_num = len(self.client.lrange("wait_queue", 0, -1))
        self.client.rpush("wait_queue", json.dumps(content))
        if wait_num == 0:
            logger.info("æ­£åœ¨æŽ’é˜Ÿä¸­ï¼ ç›®å‰æŽ’ç¬¬ä¸€ä½ï¼")
        else:
            logger.info(f"æ­£åœ¨æŽ’é˜Ÿä¸­ï¼ å‰æ–¹è¿˜æœ‰ {wait_num} ä¸ªä»»åŠ¡ï¼")
        return wait_num

    def is_my_turn(self, id):
        """
        æŽ’é˜Ÿè¿™ä¹ˆé•¿æ—¶é—´ï¼Œæ˜¯å¦è½®åˆ°æˆ‘äº†ï¼Ÿ
        """
        curr_task = json.loads(self.client.lrange("wait_queue", 0, -1)[0])
        return curr_task["id"] == id

    def update_queue(self, id):
        """
        æ›´æ–°ç­‰å¾…é˜Ÿåˆ—
        """
        task = json.loads(self.client.lrange("wait_queue", 0, -1)[0])
        if task["id"] != id:
            # ç™»è®°å¼‚å¸¸ä¿¡æ¯
            logger.warning("å½“å‰è®­ç»ƒä»»åŠ¡å¹¶ä¸æŽ’åœ¨é˜Ÿåˆ—ç¬¬ä¸€ä½ï¼Œè¯·æ£€æŸ¥Redisæ•°æ®æ­£ç¡®æ€§ï¼")
        curr_time = datetime.datetime.now()
        update_time = datetime.datetime.strftime(curr_time, "%Y-%m-%d %H:%M:%S")
        task["update_time"] = update_time
        self.client.lset("wait_queue", 0, json.dumps(task))

    def pop_wait_queue(self, id):
        """
        å¼¹å‡ºå½“å‰æŽ’ä½ç¬¬ä¸€çš„è®­ç»ƒä»»åŠ¡
        """
        task = json.loads(self.client.lrange("wait_queue", 0, -1)[0])
        if task["id"] != id:
            # ç™»è®°å¼‚å¸¸ä¿¡æ¯
            logger.warning("å½“å‰è®­ç»ƒä»»åŠ¡å¹¶ä¸æŽ’åœ¨é˜Ÿåˆ—ç¬¬ä¸€ä½ï¼Œè¯·æ£€æŸ¥Redisæ•°æ®æ­£ç¡®æ€§ï¼")
        next_task = self.client.lpop("wait_queue")
        return next_task

    def register_process(self, id, cuda, n_gpus, memo):
        """
        å°†å½“å‰è®­ç»ƒä»»åŠ¡ç™»è®°åˆ°è¿›ç¨‹ä¿¡æ¯ä¸­
        """
        curr_time = datetime.datetime.now()
        creat_time = datetime.datetime.strftime(curr_time, "%Y-%m-%d %H:%M:%S")

        content = {
            "cuda": cuda,
            "units_count": n_gpus,
            "create_time": creat_time,
            "update_time": creat_time,
            "system_pid": os.getpid(),
            "id": id,
            "task_desc": memo,
        }
        self.client.hset("running_processes", id, json.dumps(content))
        logger.info("æˆåŠŸç™»è®°è¿›ç¨‹ä½¿ç”¨ä¿¡æ¯åˆ°RedisæœåŠ¡å™¨ï¼")
        return id

    def deregister_process(self, id):
        """
        åˆ é™¤å½“å‰è®­ç»ƒä»»åŠ¡çš„ä¿¡æ¯
        """
        task = self.client.hget("running_processes", id)
        if task:
            self.client.hdel("running_processes", id)
            logger.info("æˆåŠŸåˆ é™¤RedisæœåŠ¡å™¨ä¸Šçš„è¿›ç¨‹ä½¿ç”¨ä¿¡æ¯ï¼")
        else:
            logger.warning(
                "æ— æ³•æ‰¾åˆ°å½“å‰è®­ç»ƒä»»åŠ¡åœ¨RedisæœåŠ¡å™¨ä¸Šçš„è¿›ç¨‹ä½¿ç”¨ä¿¡æ¯ï¼æˆ–è®¸å¯ä»¥è€ƒè™‘æ£€æŸ¥ä¸€ä¸‹Redisçš„æ•°æ® ðŸ¤”"
            )


class GPUQueuer:
    def __init__(self, visible_cuda="-1", n_gpus=1, memo="no memo"):
        """åˆå§‹åŒ–GPUQueuerç±»

        Args:
            visible_cuda (str, optional): å¯è§çš„ GPU ç¼–å·ï¼Œå¤šä¸ª GPU ç¼–å·ç”¨é€—å·åˆ†éš”ï¼Œå¦‚ "0,1,2,3". Defaults to "-1".
            n_gpus (int, optional): éœ€è¦çš„ GPU æ•°é‡. Defaults to 1.
            memo (str, optional): ä»»åŠ¡å¤‡æ³¨. Defaults to "no memo".
        """
        self.visible_cuda = visible_cuda
        if visible_cuda == "-1" and os.environ.get("CUDA_VISIBLE_DEVICES"):
            self.visible_cuda = str(os.environ.get("CUDA_VISIBLE_DEVICES"))
        self.n_gpus = n_gpus
        self.memo = memo
        self.redis_client = RedisClient()
        self.devices = Device.all()
        curr_time = datetime.datetime.now()
        creat_time = datetime.datetime.strftime(curr_time, "%Y-%m-%d %H:%M:%S")
        self.id = str(os.getpid()) + str(
            int(time.mktime(time.strptime(creat_time, "%Y-%m-%d %H:%M:%S")))
        )

    @logger.catch
    def start(self):
        # ---------------------------------------------------------------------------- #
        #                         èŽ·å–å½“å‰ç¬¦åˆæ¡ä»¶çš„æ‰€æœ‰å¤„ç†å™¨
        # ---------------------------------------------------------------------------- #
        self.clear_zombie_processes()
        self_occupied_gpus = self.redis_client.get_self_occupied_gpus()
        devices = Device.all()
        if self.visible_cuda != "-1":
            devices = [
                Device(index=int(device_id))
                for device_id in self.visible_cuda.split(",")
            ]

        devices = [
            device for device in devices if device.index not in self_occupied_gpus
        ]

        if len(devices) >= self.n_gpus:
            cuda = select_devices(
                devices=devices,
                format="index",
                min_count=self.n_gpus,
            )
            cuda = [str(x) for x in cuda]
            cuda = ",".join(cuda)
            self.cuda = cuda
            self.redis_client.register_process(
                self.id, cuda, n_gpus=self.n_gpus, memo=self.memo
            )
            logger.info(f"èŽ·å–åˆ°è¶³å¤Ÿçš„å¡ï¼Œå½“å‰åˆ†é…çš„å¡ä¸ºï¼š{cuda}")
            return cuda
        else:
            # ---------------------------------------------------------------------------- #
            #                         å¦‚æžœéœ€è¦æŽ’é˜Ÿå°±é€å…¥é˜Ÿåˆ—
            # ---------------------------------------------------------------------------- #
            wait_num = self.redis_client.join_wait_queue(
                self.id, n_gpus=self.n_gpus, memo=self.memo
            )

        # ---------------------------------------------------------------------------- #
        #                         æŽ’é˜Ÿæ¨¡å¼ï¼Œç­‰å¾…å¤„ç†å™¨
        # ---------------------------------------------------------------------------- #
        logger.warning("å½“å‰æ²¡æœ‰è¶³å¤Ÿçš„è®¡ç®—èµ„æºï¼Œæ­£åœ¨æŽ’é˜Ÿ...")
        wait_count = 0
        while not self.redis_client.is_my_turn(
            self.id
        ) or not is_processing_units_ready(devices, self.n_gpus):
            self.clear_zombie_processes()
            time.sleep(15)
            curr_time = str(time.strftime("%mæœˆ%dæ—¥ %H:%M:%S", time.localtime()))
            if self.redis_client.is_my_turn(self.id):
                # æ›´æ–°é˜Ÿåˆ—
                self.redis_client.update_queue(self.id)

            wait_num = len(self.redis_client.client.lrange("wait_queue", 0, -1)) - 1
            print(
                f"\ræ›´æ–°æ—¶é—´: {curr_time} | è¯¥ä»»åŠ¡ï¼ˆPIDï¼š{os.getpid()}ï¼‰éœ€è¦ {self.n_gpus} å—å¡ï¼Œå‰é¢è¿˜æœ‰ {wait_num} ä¸ªæŽ’é˜Ÿä»»åŠ¡ï¼Œå·²åˆ·æ–° {wait_count} æ¬¡",
                end="",
                flush=True,
            )

            self_occupied_gpus = self.redis_client.get_self_occupied_gpus()

            devices = Device.all()
            if self.visible_cuda != "-1":
                devices = [
                    Device(index=int(device_id))
                    for device_id in self.visible_cuda.split(",")
                ]
            devices = [
                device for device in devices if device.index not in self_occupied_gpus
            ]
            wait_count += 1

        # ---------------------------------------------------------------------------- #
        #                         æ›´æ–°å¯ç”¨å¤„ç†å™¨
        # ---------------------------------------------------------------------------- #
        cuda = select_devices(
            devices=devices,
            format="index",
            min_count=self.n_gpus,
        )
        cuda = [str(x) for x in cuda]
        cuda = ",".join(cuda)
        self.cuda = cuda
        logger.info(f"èŽ·å–åˆ°è¶³å¤Ÿçš„å¡ï¼Œå½“å‰åˆ†é…çš„å¡ä¸ºï¼š{cuda}")

        # ---------------------------------------------------------------------------- #
        #                         ä»Žé˜Ÿåˆ—ä¸­å¼¹å‡ºå¹¶æ³¨å†Œå¤„ç†å™¨å’Œè¿›ç¨‹
        # ---------------------------------------------------------------------------- #
        self.redis_client.pop_wait_queue(self.id)
        self.redis_client.register_process(
            self.id, cuda, n_gpus=self.n_gpus, memo=self.memo
        )

        return cuda

    @logger.catch
    def close(self):
        # é‡Šæ”¾èµ„æº
        self.redis_client.deregister_process(self.id)

    def clear_zombie_processes(self):
        """æ¸…ç†åƒµå°¸è¿›ç¨‹"""
        self_occupied_gpus = self.redis_client.get_self_occupied_gpus(only_gpus=False)
        queue = self.redis_client.client.lrange("wait_queue", 0, -1)
        for task in self_occupied_gpus:
            pid = int(task["system_pid"])
            if not psutil.pid_exists(pid):
                self.redis_client.client.hdel("running_processes", task["id"])
                logger.info(f"å‘çŽ° GPUå ç”¨ä¿¡æ¯ ä¸­å­˜åœ¨æ®‹ä½™æ•°æ®ï¼Œå·²æ¸…é™¤ï¼Œè¿›ç¨‹ä¸º{pid}")
        for task_json in queue:
            task = json.loads(task_json)
            pid = int(task["system_pid"])
            if not psutil.pid_exists(pid):
                self.redis_client.client.lrem("wait_queue", 1, task_json)
                logger.info(f"å‘çŽ° GPUæŽ’é˜Ÿé˜Ÿåˆ— ä¸­å­˜åœ¨æ®‹ä½™æ•°æ®ï¼Œå·²æ¸…é™¤ï¼Œè¿›ç¨‹ä¸º{pid}")

        gpu = {}

        devices = Device.all()  # or `Device.all()` to use NVML ordinal instead
        for device in devices:
            processes = device.processes()

            gpu["index"] = device.physical_index
            gpu["GPU utilization"] = f"{device.gpu_utilization()}%"
            gpu["Total memory"] = f"{device.memory_total_human()}"
            gpu["Used memory"] = f"{device.memory_used_human()}"
            gpu["Free memory"] = f"{device.memory_free_human()}"

            keys = self.redis_client.client.keys()
            for key in keys:
                if "GPU info --> " + str(device.physical_index) in key:
                    self.redis_client.client.delete(key)

            gpu_name = (
                "GPU info --> "
                + str(device.physical_index)
                + f" utilization {device.gpu_utilization()}%  Free memory {device.memory_free_human()}"
            )
            self.redis_client.client.set(gpu_name, json.dumps(gpu))

            new_processes = []
            if len(processes) > 0:
                processes = GpuProcess.take_snapshots(processes.values(), failsafe=True)
                processes.sort(key=lambda process: (process.username, process.pid))
                new_processes = []
                for snapshot in processes:
                    process = {}
                    process["pid"] = snapshot.pid
                    process["username"] = snapshot.username
                    process["time"] = snapshot.running_time_human
                    process["gpu_memory"] = (
                        snapshot.gpu_memory_human
                        if snapshot.gpu_memory_human is not NA
                        else "WDDM:N/A"
                    )
                    process["gpu_memory_percent"] = f"{snapshot.gpu_memory_percent}%"
                    process["command"] = snapshot.command
                    new_processes.append(process)
            if len(new_processes) > 0:
                self.redis_client.client.set(
                    "GPU " + str(device.physical_index) + " processes",
                    json.dumps(new_processes),
                )
            else:
                self.redis_client.client.delete(
                    "GPU " + str(device.physical_index) + " processes"
                )


def is_processing_units_ready(devices, n_gpus):
    if len(devices) < n_gpus:
        # æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å¤„ç†å™¨
        return False
    else:
        return True


def gpu_queue(func):
    """
    è£…é¥°å™¨ï¼šç­‰å¾…GPUèµ„æºå¹¶è®°å½•æŽ’é˜Ÿæ—¶é—´
    """

    @wraps(func)
    def wrapper(*args, **kwargs):
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = datetime.datetime.now()

        # GPUæŽ’é˜Ÿ
        queuer = GPUQueuer()
        queuer.start()

        # è®¡ç®—æŽ’é˜Ÿæ—¶é—´
        end_time = datetime.datetime.now()
        time_diff = end_time - start_time

        # è®¡ç®—å¤©ã€å°æ—¶ã€åˆ†é’Ÿã€ç§’
        days = time_diff.days
        seconds = time_diff.seconds
        hours = seconds // 3600
        seconds %= 3600
        minutes = seconds // 60
        seconds %= 60

        queue_time = f"{days}å¤© {hours}å°æ—¶ {minutes}åˆ†é’Ÿ {seconds}ç§’"
        logger.info(f"æŽ’é˜Ÿæ—¶é—´ï¼š{queue_time}")

        # è°ƒç”¨åŽŸå§‹å‡½æ•°
        return func(*args, **kwargs)

    return wrapper
